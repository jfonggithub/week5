{
 "metadata": {
  "name": "",
  "signature": "sha256:35b7ec0572a8d64c6a024f17749fca0c8ed5d12ff426a0d8c51adbc6c286a132"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Boston Housing Assignment\n",
      "\n",
      "In this assignment you'll be using linear regression to estimate the cost of house in boston, using a well known dataset.\n",
      "\n",
      "Goals:\n",
      "+  Measure the performance of the model I created using $R^{2}$ and MSE\n",
      "> Learn how to use sklearn.metrics.r2_score and sklearn.metrics.mean_squared_error\n",
      "+  Implement a new model using L2 regularization\n",
      "> Use sklearn.linear_model.Ridge or sklearn.linear_model.Lasso \n",
      "+  Get the best model you can by optimizing the regularization parameter.   "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn import datasets\n",
      "import pandas as pd\n",
      "from sklearn.preprocessing import StandardScaler\n",
      "from sklearn.cross_validation import train_test_split\n",
      "from sklearn.metrics import mean_squared_error\n",
      "from sklearn.metrics import r2_score\n",
      "from sklearn.linear_model import LinearRegression"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 20
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "bean = datasets.load_boston()\n",
      "print bean.DESCR"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Boston House Prices dataset\n",
        "\n",
        "Notes\n",
        "------\n",
        "Data Set Characteristics:  \n",
        "\n",
        "    :Number of Instances: 506 \n",
        "\n",
        "    :Number of Attributes: 13 numeric/categorical predictive\n",
        "    \n",
        "    :Median Value (attribute 14) is usually the target\n",
        "\n",
        "    :Attribute Information (in order):\n",
        "        - CRIM     per capita crime rate by town\n",
        "        - ZN       proportion of residential land zoned for lots over 25,000 sq.ft.\n",
        "        - INDUS    proportion of non-retail business acres per town\n",
        "        - CHAS     Charles River dummy variable (= 1 if tract bounds river; 0 otherwise)\n",
        "        - NOX      nitric oxides concentration (parts per 10 million)\n",
        "        - RM       average number of rooms per dwelling\n",
        "        - AGE      proportion of owner-occupied units built prior to 1940\n",
        "        - DIS      weighted distances to five Boston employment centres\n",
        "        - RAD      index of accessibility to radial highways\n",
        "        - TAX      full-value property-tax rate per $10,000\n",
        "        - PTRATIO  pupil-teacher ratio by town\n",
        "        - B        1000(Bk - 0.63)^2 where Bk is the proportion of blacks by town\n",
        "        - LSTAT    % lower status of the population\n",
        "        - MEDV     Median value of owner-occupied homes in $1000's\n",
        "\n",
        "    :Missing Attribute Values: None\n",
        "\n",
        "    :Creator: Harrison, D. and Rubinfeld, D.L.\n",
        "\n",
        "This is a copy of UCI ML housing dataset.\n",
        "http://archive.ics.uci.edu/ml/datasets/Housing\n",
        "\n",
        "\n",
        "This dataset was taken from the StatLib library which is maintained at Carnegie Mellon University.\n",
        "\n",
        "The Boston house-price data of Harrison, D. and Rubinfeld, D.L. 'Hedonic\n",
        "prices and the demand for clean air', J. Environ. Economics & Management,\n",
        "vol.5, 81-102, 1978.   Used in Belsley, Kuh & Welsch, 'Regression diagnostics\n",
        "...', Wiley, 1980.   N.B. Various transformations are used in the table on\n",
        "pages 244-261 of the latter.\n",
        "\n",
        "The Boston house-price data has been used in many machine learning papers that address regression\n",
        "problems.   \n",
        "     \n",
        "**References**\n",
        "\n",
        "   - Belsley, Kuh & Welsch, 'Regression diagnostics: Identifying Influential Data and Sources of Collinearity', Wiley, 1980. 244-261.\n",
        "   - Quinlan,R. (1993). Combining Instance-Based and Model-Based Learning. In Proceedings on the Tenth International Conference of Machine Learning, 236-243, University of Massachusetts, Amherst. Morgan Kaufmann.\n",
        "   - many more! (see http://archive.ics.uci.edu/ml/datasets/Housing)\n",
        "\n"
       ]
      }
     ],
     "prompt_number": 21
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def load_boston():\n",
      "    scaler = StandardScaler()\n",
      "    boston = datasets.load_boston()\n",
      "    X=boston.data\n",
      "    y=boston.target\n",
      "    X = scaler.fit_transform(X)\n",
      "    return train_test_split(X,y)\n",
      "    "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 22
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "X_train, X_test, y_train, y_test = load_boston()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 23
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "X_train.shape"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 24,
       "text": [
        "(379L, 13L)"
       ]
      }
     ],
     "prompt_number": 24
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Fitting a Linear Regression\n",
      "\n",
      "It's as easy as instantiating a new regression object (line 1) and giving your regression object your training data\n",
      "(line 2) by calling .fit(independent variables, dependent variable)\n",
      "\n"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\n",
      "clf = LinearRegression()\n",
      "clf.fit(X_train, y_train)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 25,
       "text": [
        "LinearRegression(copy_X=True, fit_intercept=True, normalize=False)"
       ]
      }
     ],
     "prompt_number": 25
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Making a Prediction\n",
      "X_test is our holdout set of data.  We know the answer (y_test) but the computer does not.   \n",
      "\n",
      "Using the command below, I create a tuple for each observation, where I'm combining the real value (y_test) with\n",
      "the value our regressor predicts (clf.predict(X_test))\n",
      "\n",
      "Use a similiar format to get your r2 and mse metrics working.  Using the [scikit learn api](http://scikit-learn.org/stable/modules/model_evaluation.html) if you need help!"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "zip (y_test, clf.predict(X_test))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 26,
       "text": [
        "[(21.399999999999999, 22.054176495296137),\n",
        " (16.100000000000001, 21.14467377967425),\n",
        " (20.300000000000001, 18.537545030949534),\n",
        " (19.5, 20.244931823204929),\n",
        " (18.899999999999999, 23.889887068959428),\n",
        " (26.399999999999999, 22.466975156844079),\n",
        " (50.0, 41.524709709295848),\n",
        " (7.2000000000000002, 17.793377107238697),\n",
        " (25.0, 23.587015962141038),\n",
        " (8.3000000000000007, 13.488675728639734),\n",
        " (24.399999999999999, 28.359056033467674),\n",
        " (20.600000000000001, 19.451340327210332),\n",
        " (13.800000000000001, 16.188296557871862),\n",
        " (28.399999999999999, 28.576935023848165),\n",
        " (20.399999999999999, 20.738039474858201),\n",
        " (43.5, 39.548964588852506),\n",
        " (22.300000000000001, 26.437472765232712),\n",
        " (19.600000000000001, 19.596228721233391),\n",
        " (21.5, 21.651839678297833),\n",
        " (21.600000000000001, 25.700199090943112),\n",
        " (18.300000000000001, 20.26739844708526),\n",
        " (11.9, 22.832318592526754),\n",
        " (25.100000000000001, 30.712448910922333),\n",
        " (13.5, 12.989055651555969),\n",
        " (19.600000000000001, 22.638083484309597),\n",
        " (21.699999999999999, 21.406429866881474),\n",
        " (23.899999999999999, 27.89645839925894),\n",
        " (19.100000000000001, 24.199573714556635),\n",
        " (41.299999999999997, 33.365746148802721),\n",
        " (17.399999999999999, 17.114163797894356),\n",
        " (31.199999999999999, 28.888002568439308),\n",
        " (35.399999999999999, 34.028021345355626),\n",
        " (8.6999999999999993, 8.1366361930158391),\n",
        " (10.4, 6.5952553076430576),\n",
        " (24.0, 25.093403996733169),\n",
        " (50.0, 45.25831164200882),\n",
        " (13.9, 13.13954222160797),\n",
        " (31.0, 34.389340595225065),\n",
        " (33.100000000000001, 32.628384769523478),\n",
        " (27.100000000000001, 18.63927973602167),\n",
        " (23.199999999999999, 22.187398754416208),\n",
        " (18.399999999999999, 15.887455721707877),\n",
        " (17.5, 18.711250630558194),\n",
        " (23.800000000000001, 22.878657617154222),\n",
        " (22.699999999999999, 23.917902906527413),\n",
        " (19.899999999999999, 19.425992744226853),\n",
        " (13.6, 12.078516418815802),\n",
        " (20.5, 19.700498699745214),\n",
        " (21.899999999999999, 38.548196358312765),\n",
        " (37.200000000000003, 32.949126117770049),\n",
        " (19.100000000000001, 19.444504870183508),\n",
        " (25.0, 22.062745012939974),\n",
        " (5.5999999999999996, 11.711978652221189),\n",
        " (20.699999999999999, 21.65423244680381),\n",
        " (48.799999999999997, 40.939864514692779),\n",
        " (15.300000000000001, 22.322968563769347),\n",
        " (23.600000000000001, 29.045312220658651),\n",
        " (27.5, 32.69518640541834),\n",
        " (36.200000000000003, 27.759167708092484),\n",
        " (13.300000000000001, 13.543788859803037),\n",
        " (19.0, 13.872919732932255),\n",
        " (19.199999999999999, 20.14498381141544),\n",
        " (17.899999999999999, 0.51342166264750944),\n",
        " (10.199999999999999, 15.956281992208737),\n",
        " (22.399999999999999, 23.187167911299646),\n",
        " (38.700000000000003, 35.438888427479391),\n",
        " (23.199999999999999, 25.698601794844588),\n",
        " (22.399999999999999, 23.751180935639603),\n",
        " (45.399999999999999, 38.224474097330848),\n",
        " (18.5, 12.550296709044206),\n",
        " (23.800000000000001, 26.189269026461805),\n",
        " (17.800000000000001, 16.290591582190771),\n",
        " (19.300000000000001, 17.002804309016863),\n",
        " (24.5, 27.549227944467479),\n",
        " (31.699999999999999, 33.020502851382361),\n",
        " (33.299999999999997, 35.957879344830829),\n",
        " (16.199999999999999, 15.240186648252557),\n",
        " (20.600000000000001, 22.777384429542501),\n",
        " (50.0, 39.205257313354224),\n",
        " (14.9, 17.779710566100338),\n",
        " (20.5, 23.536384062448498),\n",
        " (34.600000000000001, 34.348358945734596),\n",
        " (15.6, 12.40630923883417),\n",
        " (15.4, 18.179204921486896),\n",
        " (37.600000000000001, 37.272572550069519),\n",
        " (36.5, 36.033934076800989),\n",
        " (31.5, 32.524909007704089),\n",
        " (17.100000000000001, 19.352315058487047),\n",
        " (19.5, 18.428825410457925),\n",
        " (14.9, 14.723498401005859),\n",
        " (23.399999999999999, 23.809396586235739),\n",
        " (23.699999999999999, 27.00068508143486),\n",
        " (13.6, 13.855153272140635),\n",
        " (19.300000000000001, 21.383126540046394),\n",
        " (24.399999999999999, 24.135393089468899),\n",
        " (20.199999999999999, 16.462273663040019),\n",
        " (20.100000000000001, 18.737325481471988),\n",
        " (18.5, 25.344373259288147),\n",
        " (20.0, 22.323681138436221),\n",
        " (27.0, 33.879364813906264),\n",
        " (17.600000000000001, 15.848935823211622),\n",
        " (5.0, 9.081474102426375),\n",
        " (15.4, 15.287828460347477),\n",
        " (26.199999999999999, 23.852599812110867),\n",
        " (19.399999999999999, 23.361731665070295),\n",
        " (16.600000000000001, 16.978754110492165),\n",
        " (25.0, 25.261033243221547),\n",
        " (14.4, 3.1302267791420704),\n",
        " (17.399999999999999, 15.86182121663367),\n",
        " (31.600000000000001, 33.002158175865119),\n",
        " (13.4, 12.810690512712657),\n",
        " (8.3000000000000007, 9.2410398636537767),\n",
        " (13.800000000000001, 5.4534509750522098),\n",
        " (24.300000000000001, 19.740798989219872),\n",
        " (30.100000000000001, 35.364644843194846),\n",
        " (21.699999999999999, 24.189857756760063),\n",
        " (20.899999999999999, 21.624400255956921),\n",
        " (22.800000000000001, 28.897366119721411),\n",
        " (27.5, 24.684521777056723),\n",
        " (42.799999999999997, 29.411234004473076),\n",
        " (24.699999999999999, 24.995784825165419),\n",
        " (50.0, 25.351960537075001),\n",
        " (19.399999999999999, 16.512574535973933),\n",
        " (20.399999999999999, 19.926563734753337),\n",
        " (27.899999999999999, 20.513575678074783),\n",
        " (20.199999999999999, 22.941668228803646),\n",
        " (14.199999999999999, 18.408889748038479)]"
       ]
      }
     ],
     "prompt_number": 26
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# LAB STARTS HERE...\n",
      "# check the r2 score of the existing model \n",
      "# note that every time I press Run All, this score changes. \n",
      "# Not sure if it's a rounding issue.\n",
      "# from the documentation:\n",
      "# R^2 (coefficient of determination) regression score function.\n",
      "# Best possible score is 1.0, lower values are worse.\n",
      "r2_score(y_test, clf.predict(X_test), sample_weight=None)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 41,
       "text": [
        "0.70008170031964845"
       ]
      }
     ],
     "prompt_number": 41
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# check my Anaconda version. Doesn't seem to be causing issues.\n",
      "import sys\n",
      "print (sys.version)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "2.7.8 |Anaconda 2.1.0 (64-bit)| (default, Jul  2 2014, 15:12:11) [MSC v.1500 64 bit (AMD64)]\n"
       ]
      }
     ],
     "prompt_number": 43
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# check the mean squared error of the existing model\n",
      "# from the documentation:\n",
      "# Mean squared error regression loss\n",
      "# the best value is 0.0\n",
      "mean_squared_error(y_test, clf.predict(X_test), sample_weight=None)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 44,
       "text": [
        "26.498835181909829"
       ]
      }
     ],
     "prompt_number": 44
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# implement a new model using sklearn.linear_model.Ridge\n",
      "from sklearn.linear_model import Ridge"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 36
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# start with alpha = 1.0\n",
      "clf = Ridge(alpha=1.0)\n",
      "clf.fit(X_train, y_train)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 51,
       "text": [
        "Ridge(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=None,\n",
        "   normalize=False, solver='auto', tol=0.001)"
       ]
      }
     ],
     "prompt_number": 51
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# look at actual and predicted values\n",
      "zip (y_test, clf.predict(X_test))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 46,
       "text": [
        "[(21.399999999999999, 22.016930072886073),\n",
        " (16.100000000000001, 21.09953598337713),\n",
        " (20.300000000000001, 18.533606113122445),\n",
        " (19.5, 20.244740237428708),\n",
        " (18.899999999999999, 23.863769439692021),\n",
        " (26.399999999999999, 22.41672431425722),\n",
        " (50.0, 41.508751380582616),\n",
        " (7.2000000000000002, 17.790283189369827),\n",
        " (25.0, 23.576875283548443),\n",
        " (8.3000000000000007, 13.479603763123675),\n",
        " (24.399999999999999, 28.316764324216241),\n",
        " (20.600000000000001, 19.431267499343491),\n",
        " (13.800000000000001, 16.142184548633658),\n",
        " (28.399999999999999, 28.573058543522968),\n",
        " (20.399999999999999, 20.753637828045051),\n",
        " (43.5, 39.499632893845138),\n",
        " (22.300000000000001, 26.414587790015986),\n",
        " (19.600000000000001, 19.63156862282478),\n",
        " (21.5, 21.689889010439064),\n",
        " (21.600000000000001, 25.683945078637393),\n",
        " (18.300000000000001, 20.284082803992295),\n",
        " (11.9, 22.831433973271675),\n",
        " (25.100000000000001, 30.698441062288758),\n",
        " (13.5, 13.030239203764912),\n",
        " (19.600000000000001, 22.585718201454895),\n",
        " (21.699999999999999, 21.41207634798101),\n",
        " (23.899999999999999, 27.910344967702226),\n",
        " (19.100000000000001, 24.170426250526624),\n",
        " (41.299999999999997, 33.324876194350026),\n",
        " (17.399999999999999, 17.153283601512889),\n",
        " (31.199999999999999, 28.918388793751767),\n",
        " (35.399999999999999, 33.974795643102894),\n",
        " (8.6999999999999993, 8.1656636288135616),\n",
        " (10.4, 6.6038527828291738),\n",
        " (24.0, 25.056182211082707),\n",
        " (50.0, 45.215157453992006),\n",
        " (13.9, 13.174260378735216),\n",
        " (31.0, 34.35417769838002),\n",
        " (33.100000000000001, 32.60124999172843),\n",
        " (27.100000000000001, 18.660041191118459),\n",
        " (23.199999999999999, 22.157281084547588),\n",
        " (18.399999999999999, 15.92477224690883),\n",
        " (17.5, 18.725810603485044),\n",
        " (23.800000000000001, 22.855450805840427),\n",
        " (22.699999999999999, 23.933261796526345),\n",
        " (19.899999999999999, 19.426850365432465),\n",
        " (13.6, 12.11227957033179),\n",
        " (20.5, 19.627911757286483),\n",
        " (21.899999999999999, 38.56575559440607),\n",
        " (37.200000000000003, 32.905410032107454),\n",
        " (19.100000000000001, 19.421874503531278),\n",
        " (25.0, 22.084009065901675),\n",
        " (5.5999999999999996, 11.73255251078448),\n",
        " (20.699999999999999, 21.675009085410405),\n",
        " (48.799999999999997, 40.912491094680533),\n",
        " (15.300000000000001, 22.35111200887026),\n",
        " (23.600000000000001, 29.009652662668891),\n",
        " (27.5, 32.672777418861074),\n",
        " (36.200000000000003, 27.708302987949857),\n",
        " (13.300000000000001, 13.586789470029835),\n",
        " (19.0, 13.857258500047299),\n",
        " (19.199999999999999, 20.180097584834897),\n",
        " (17.899999999999999, 0.49869222351691178),\n",
        " (10.199999999999999, 15.91856546055114),\n",
        " (22.399999999999999, 23.190410276394534),\n",
        " (38.700000000000003, 35.44842594872916),\n",
        " (23.199999999999999, 25.685296540466069),\n",
        " (22.399999999999999, 23.769389438740703),\n",
        " (45.399999999999999, 38.166760762497503),\n",
        " (18.5, 12.585902245108413),\n",
        " (23.800000000000001, 26.161097027959336),\n",
        " (17.800000000000001, 16.330908093148636),\n",
        " (19.300000000000001, 17.011181774290847),\n",
        " (24.5, 27.553065111896256),\n",
        " (31.699999999999999, 32.985515906146063),\n",
        " (33.299999999999997, 35.955647977542547),\n",
        " (16.199999999999999, 15.270528624904616),\n",
        " (20.600000000000001, 22.779629768701664),\n",
        " (50.0, 39.178359280578938),\n",
        " (14.9, 17.782178304335407),\n",
        " (20.5, 23.520794308213382),\n",
        " (34.600000000000001, 34.352036497093408),\n",
        " (15.6, 12.467308366091473),\n",
        " (15.4, 18.188689549844892),\n",
        " (37.600000000000001, 37.232425750636004),\n",
        " (36.5, 35.985504550751337),\n",
        " (31.5, 32.497524232458055),\n",
        " (17.100000000000001, 19.389197678721658),\n",
        " (19.5, 18.442416336226454),\n",
        " (14.9, 14.738531091305122),\n",
        " (23.399999999999999, 23.81706337099272),\n",
        " (23.699999999999999, 26.953183310824834),\n",
        " (13.6, 13.976953204730393),\n",
        " (19.300000000000001, 21.453333377797296),\n",
        " (24.399999999999999, 24.159859416430919),\n",
        " (20.199999999999999, 16.485719190518775),\n",
        " (20.100000000000001, 18.709483871474415),\n",
        " (18.5, 25.349427634425243),\n",
        " (20.0, 22.303502093614846),\n",
        " (27.0, 33.842828683582354),\n",
        " (17.600000000000001, 15.864510584869299),\n",
        " (5.0, 9.1254916728655218),\n",
        " (15.4, 15.338412455196021),\n",
        " (26.199999999999999, 23.888621151867536),\n",
        " (19.399999999999999, 23.390895058750107),\n",
        " (16.600000000000001, 16.98875459364189),\n",
        " (25.0, 25.264226634660382),\n",
        " (14.4, 3.1938968354011976),\n",
        " (17.399999999999999, 15.899541776680834),\n",
        " (31.600000000000001, 32.952045858970088),\n",
        " (13.4, 12.840413284740251),\n",
        " (8.3000000000000007, 9.2454579141966224),\n",
        " (13.800000000000001, 5.4509138684458307),\n",
        " (24.300000000000001, 19.771368477430418),\n",
        " (30.100000000000001, 35.304591577307491),\n",
        " (21.699999999999999, 24.208159804992064),\n",
        " (20.899999999999999, 21.662935772781697),\n",
        " (22.800000000000001, 28.836258402106228),\n",
        " (27.5, 24.709402564976997),\n",
        " (42.799999999999997, 29.486836070821418),\n",
        " (24.699999999999999, 25.0320968319086),\n",
        " (50.0, 25.286822347364105),\n",
        " (19.399999999999999, 16.521006626298099),\n",
        " (20.399999999999999, 19.95512345663635),\n",
        " (27.899999999999999, 20.45674299037054),\n",
        " (20.199999999999999, 22.931392209240304),\n",
        " (14.199999999999999, 18.391242966711289)]"
       ]
      }
     ],
     "prompt_number": 46
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# check the r2 score of the new model\n",
      "r2_score(y_test, clf.predict(X_test), sample_weight=None)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 52,
       "text": [
        "0.70008170031964845"
       ]
      }
     ],
     "prompt_number": 52
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# The new r2 score is the same as the one from the existing model\n",
      "# adjust alpha to improve this score\n",
      "clf = Ridge(alpha=0.8)\n",
      "clf.fit(X_train, y_train)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 53,
       "text": [
        "Ridge(alpha=0.8, copy_X=True, fit_intercept=True, max_iter=None,\n",
        "   normalize=False, solver='auto', tol=0.001)"
       ]
      }
     ],
     "prompt_number": 53
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# check the r2 score again, it improves slightly\n",
      "r2_score(y_test, clf.predict(X_test), sample_weight=None)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 54,
       "text": [
        "0.70008242449289848"
       ]
      }
     ],
     "prompt_number": 54
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# check the mean squared error, it improves slightly\n",
      "mean_squared_error(y_test, clf.predict(X_test), sample_weight=None)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 55,
       "text": [
        "26.498771198659682"
       ]
      }
     ],
     "prompt_number": 55
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# adjust alpha again\n",
      "clf = Ridge(alpha=0.5)\n",
      "clf.fit(X_train, y_train)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 56,
       "text": [
        "Ridge(alpha=0.5, copy_X=True, fit_intercept=True, max_iter=None,\n",
        "   normalize=False, solver='auto', tol=0.001)"
       ]
      }
     ],
     "prompt_number": 56
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# check the r2 score again, it improves slightly, \n",
      "# try a much lower alpha\n",
      "r2_score(y_test, clf.predict(X_test), sample_weight=None)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 57,
       "text": [
        "0.7000832468907825"
       ]
      }
     ],
     "prompt_number": 57
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# adjust alpha again\n",
      "clf = Ridge(alpha=0.1)\n",
      "clf.fit(X_train, y_train)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 58,
       "text": [
        "Ridge(alpha=0.1, copy_X=True, fit_intercept=True, max_iter=None,\n",
        "   normalize=False, solver='auto', tol=0.001)"
       ]
      }
     ],
     "prompt_number": 58
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# check the r2 score again, it gets worse slightly, \n",
      "# trying a lower alpha just to see if it gets worse\n",
      "r2_score(y_test, clf.predict(X_test), sample_weight=None)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 59,
       "text": [
        "0.70008381077079318"
       ]
      }
     ],
     "prompt_number": 59
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# adjust alpha again\n",
      "clf = Ridge(alpha=0.01)\n",
      "clf.fit(X_train, y_train)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 60,
       "text": [
        "Ridge(alpha=0.01, copy_X=True, fit_intercept=True, max_iter=None,\n",
        "   normalize=False, solver='auto', tol=0.001)"
       ]
      }
     ],
     "prompt_number": 60
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# check the r2 score again, it gets slighlt better unexpectedly\n",
      "r2_score(y_test, clf.predict(X_test), sample_weight=None)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 61,
       "text": [
        "0.70008384774513699"
       ]
      }
     ],
     "prompt_number": 61
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# check the mean squared error, it improves slightly\n",
      "mean_squared_error(y_test, clf.predict(X_test), sample_weight=None)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 62,
       "text": [
        "26.498645449325508"
       ]
      }
     ],
     "prompt_number": 62
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# keep tweaking alpha and checking r2 score and mean squared error\n",
      "clf = Ridge(alpha=0.001)\n",
      "clf.fit(X_train, y_train)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 63,
       "text": [
        "Ridge(alpha=0.001, copy_X=True, fit_intercept=True, max_iter=None,\n",
        "   normalize=False, solver='auto', tol=0.001)"
       ]
      }
     ],
     "prompt_number": 63
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "r2_score(y_test, clf.predict(X_test), sample_weight=None)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 64,
       "text": [
        "0.70008384954455583"
       ]
      }
     ],
     "prompt_number": 64
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "mean_squared_error(y_test, clf.predict(X_test), sample_weight=None)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 65,
       "text": [
        "26.498645290340527"
       ]
      }
     ],
     "prompt_number": 65
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# try adjusting the max_iter parameter, didn't seem to help\n",
      "clf = Ridge(alpha=0.001, max_iter=1000)\n",
      "clf.fit(X_train, y_train)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 66,
       "text": [
        "Ridge(alpha=0.001, copy_X=True, fit_intercept=True, max_iter=1000,\n",
        "   normalize=False, solver='auto', tol=0.001)"
       ]
      }
     ],
     "prompt_number": 66
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "r2_score(y_test, clf.predict(X_test), sample_weight=None)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 67,
       "text": [
        "0.70008384954455583"
       ]
      }
     ],
     "prompt_number": 67
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "mean_squared_error(y_test, clf.predict(X_test), sample_weight=None)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 68,
       "text": [
        "26.498645290340527"
       ]
      }
     ],
     "prompt_number": 68
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# try setting normalize = True, improves slightly\n",
      "clf = Ridge(alpha=0.001, max_iter=1000, normalize=True)\n",
      "clf.fit(X_train, y_train) "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 70,
       "text": [
        "Ridge(alpha=0.001, copy_X=True, fit_intercept=True, max_iter=1000,\n",
        "   normalize=True, solver='auto', tol=0.001)"
       ]
      }
     ],
     "prompt_number": 70
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "r2_score(y_test, clf.predict(X_test), sample_weight=None)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 71,
       "text": [
        "0.70008952904125854"
       ]
      }
     ],
     "prompt_number": 71
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "mean_squared_error(y_test, clf.predict(X_test), sample_weight=None)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 72,
       "text": [
        "26.498143486858716"
       ]
      }
     ],
     "prompt_number": 72
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# use a different solver, improves a bit more\n",
      "clf = Ridge(alpha=0.001, max_iter=1000, normalize=True, solver='sparse_cg')\n",
      "clf.fit(X_train, y_train) "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 77,
       "text": [
        "Ridge(alpha=0.001, copy_X=True, fit_intercept=True, max_iter=1000,\n",
        "   normalize=True, solver='sparse_cg', tol=0.001)"
       ]
      }
     ],
     "prompt_number": 77
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "r2_score(y_test, clf.predict(X_test), sample_weight=None)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 78,
       "text": [
        "0.70020637031463939"
       ]
      }
     ],
     "prompt_number": 78
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "mean_squared_error(y_test, clf.predict(X_test), sample_weight=None)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 79,
       "text": [
        "26.487820149973089"
       ]
      }
     ],
     "prompt_number": 79
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# it seems that the above model is as good as it can get..."
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}